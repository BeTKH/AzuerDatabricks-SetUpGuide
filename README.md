# Azure Databricks Setup Guide

## Overview

The Azure Databricks setup guide demonstrates how to create a Databricks workspace, link it to Azure, and effectively manage data pipelines. This setup is ideal for anyone looking to establish a cloud-based analytics environment and streamline data processing tasks.

---

## Key Highlights

### Setting Up Databricks and Azure Integration

This guide covers the essential steps needed to link Databricks with an Azure storage account:

- **Step 1: Databricks Workspace Setup** - set up a new Databricks workspace in Azure, configure security settings, and link it to your Azure storage following `DataBricksSetup.pdf` file.

- **Step 2: Uploading Data** - Upload sample data files from the `InputData` folder in the repo to Azure storage.

- **Step 3: Configuring GitHub Integration** - Integrate Databricks with GitHub for version control and seamless data management. Clone the git repo, manipulate data using Python `Setup.py`, and push changes back to GitHub.

### Data Manipulation and Analysis

The guide includes:

- Instructions for manipulating data using Databricks notebooks.
- Steps for saving cleaned data files back to Azure.
- Capture of evidence through screenshots and renamed CSV files to demonstrate data processing.

---

This guide is a personal documentation to show how to set up an Azure Databricks workspace which can be used in a data engineering project.
